import mylib

type Token {    
    kind   Kind
    lexeme u8[]
}


type mystruct {
    x float
    y int
}

type myenum {
    One
    Two
}

func main() void {
    var x = 3;
}

func f() int {
    printf("hello");
}


type Kind {
    Invalid
    Eof
    Newline
    Identifier
    Number
    StringLiteral
    LParen
    RParen
    LBracket
    RBracket
    LBrace
    RBrace
    Period
    Comma
    Colon
    Semicolon
    Tilde
    Equal
    EqualEqual
    AngleBracketLeft
    AngleBracketLeftEqual
    AngleBracketRight
    AngleBracketRightEqual
    Asterisk
    AsteriskEqual
    Slash
    SlashEqual
    Plus
    PlusEqual
    Minus
    MinusEqual
    Ampersand
    AmpersandEqual
    Pipe
    PipeEqual
    Caret
    CaretEqual
    Percent
    PercentEqual
    LineComment
    MultilineComment
    KeywordIf
    KeywordEnd
    KeywordFor
    KeywordType
    KeywordFunc
    KeywordProc
    KeywordExpr
    KeywordElif
    KeywordElse
    KeywordCase
    KeywordMacro
    KeywordSwitch
    KeywordImport
    KeywordExport
}

type Token
{
    kind   Kind
    lexeme u8[]
}

















type Kind {
    Invalid
    Eof
    Newline
    Identifier
    Number
    StringLiteral
    LParen
    RParen
    LBracket
    RBracket
    LBrace
    RBrace
    Period
    Comma
    Colon
    Semicolon
    Tilde
    Equal
    EqualEqual
    AngleBracketLeft
    AngleBracketLeftEqual
    AngleBracketRight
    AngleBracketRightEqual
    Asterisk
    AsteriskEqual
    Slash
    SlashEqual
    Plus
    PlusEqual
    Minus
    MinusEqual
    Ampersand
    AmpersandEqual
    Pipe
    PipeEqual
    Caret
    CaretEqual
    Percent
    PercentEqual
    LineComment
    MultilineComment
    KeywordIf
    KeywordEnd
    KeywordFor
    KeywordType
    KeywordFunc
    KeywordProc
    KeywordExpr
    KeywordElif
    KeywordElse
    KeywordCase
    KeywordMacro
    KeywordMatch
    KeywordImport
    KeywordExport
}

type Token {
    kind   Kind
    lexeme u8[]
}

type Lexer {
    text   u8[:0] // The syntax [:x]T describes a pointer that has a length determined by a sentinel value.
    cursor u8
}

type State {
    Start
    Identifier
    Number
    SingleQuote
    DoubleQuote
    LineComment
    MultilineComment
    MultilineCommentEnd
    Equal
    AngleBracketLeft
    AngleBracketRight
    Asterisk
    Slash
    Percent
    Plus
    Minus
    Ampersand
    Pipe
    Caret
}

func match_keyword(lexeme u8[]) Kind {
    match lexeme {
        "if"     : return KeywordIf
        "end"    : return KeywordEnd
        "for"    : return KeywordFor
        else     : return Identifier
    }
}


func next(lexer Lexer) Token {
    use lexer.cursor as cursor
    use lexer.text as text

    var start = cursor
    var state = Start

    for i, c in text {
        match state {
            Start:
                match c {
                    ' ': 
                    '\t': 
                        start += 1
                        continue
                    '\n':
                    '\r': 
                        cursor = cursor + i + 1
                        return Token(Newline, text[start .. cursor])
                    'a'..'z':
                    'A'..'Z':
                    '_': 
                        state = Identifier
                        start = cursor + i
                    '0': 
                    '1'..'9': 
                        state = Number
                        start = cursor + i
                    '\'': 
                        state = SingleQuote
                        start = cursor + i
                    '"': 
                        state = DoubleQuote
                        start = cursor + i
                    '=': 
                        state = Equal
                        start = cursor + i
                    '<': 
                        state = AngleBracketLeft
                        start = cursor + i
                    '>': 
                        state = AngleBracketRight
                        start = cursor + i
                    '*': 
                        state = Asterisk
                        start = cursor + i
                    '/': 
                        state = Slash
                        start = cursor + i
                    '%': 
                        state = Percent
                        start = cursor + i
                    '+': 
                        state = Plus
                        start = cursor + i
                    '-': 
                        state = Minus
                        start = cursor + i
                    '&': 
                        state = Ampersand
                        start = cursor + i
                    '|': 
                        state = Pipe
                        start = cursor + i
                    '^': 
                        state = Caret
                        start = cursor + i
                    '{': 
                        cursor = cursor + i + 1
                        return Token(LBrace, text[start .. cursor])
                    '}': 
                        cursor = cursor + i + 1
                        return Token(RBrace, text[start .. cursor])
                    '[': 
                        cursor = cursor + i + 1
                        return Token(LBracket, text[start .. cursor])
                    ']': 
                        cursor = cursor + i + 1
                        return Token(RBracket, text[start .. cursor])
                    '(': 
                        cursor = cursor + i + 1
                        return Token(LParen, text[start .. cursor])
                    ')': 
                        cursor = cursor + i + 1
                        return Token(RParen, text[start .. cursor])
                    '.': 
                        cursor = cursor + i + 1
                        return Token(Period, text[start .. cursor])
                    ':': 
                        cursor = cursor + i + 1
                        return Token(Colon, text[start .. cursor])
                    ',': 
                        cursor = cursor + i + 1
                        return Token(Comma, text[start .. cursor])
                    ';': 
                        cursor = cursor + i + 1
                        return Token(Semicolon, text[start .. cursor])
                    '~': 
                        cursor = cursor + i + 1
                        return Token(Tilde, text[start .. cursor])
                    else: 
                        cursor = cursor + i + 1
                        return Token(Invalid, text[start .. cursor])
                }
            
            Identifier:
                match c {
                    'a'..'z':
                    'A'..'Z':
                    '0'..'9':
                    '_':
                        continue
                    else:
                        cursor = cursor + i
                        lexeme = text[start .. cursor]
                        kind = match_keyword(lexeme)
                        return Token(kind, lexeme)
                }


    
        }
    }
}












































type Kind {
    Invalid
    Eof
    Newline
    Identifier
    Number
    StringLiteral
    LParen
    RParen
    LBracket
    RBracket
    LBrace
    RBrace
    Period
    Comma
    Colon
    Semicolon
    Tilde
    Equal
    EqualEqual
    AngleBracketLeft
    AngleBracketLeftEqual
    AngleBracketRight
    AngleBracketRightEqual
    Asterisk
    AsteriskEqual
    Slash
    SlashEqual
    Plus
    PlusEqual
    Minus
    MinusEqual
    Ampersand
    AmpersandEqual
    Pipe
    PipeEqual
    Caret
    CaretEqual
    Percent
    PercentEqual
    LineComment
    MultilineComment
    KeywordIf
    KeywordEnd
    KeywordFor
    KeywordType
    KeywordFunc
    KeywordProc
    KeywordExpr
    KeywordElif
    KeywordElse
    KeywordCase
    KeywordMacro
    KeywordMatch
    KeywordImport
    KeywordExport
}

type Token {
    kind   Kind
    lexeme u8[]
}

type Lexer {
    text   u8[:0]
    cursor u8
}

type State {
    Start
    Identifier
    Number
    SingleQuote
    DoubleQuote
    LineComment
    MultilineComment
    Equal
    AngleBracketLeft
    AngleBracketRight
    Asterisk
    Slash
    Percent
    Plus
    Minus
    Ampersand
    Pipe
    Caret
    Dot
    DotDot
}

func match_keyword(lexeme u8[]) Kind {
    match lexeme {
        "if": return KeywordIf
        "end": return KeywordEnd
        "for": return KeywordFor
        "type": return KeywordType
        "func": return KeywordFunc
        "proc": return KeywordProc
        "expr": return KeywordExpr
        "elif": return KeywordElif
        "else": return KeywordElse
        "case": return KeywordCase
        "macro": return KeywordMacro
        "match": return KeywordMatch
        "import": return KeywordImport
        "export": return KeywordExport
        else: return Identifier
    }
}

func next(lexer Lexer) Token {
    use lexer.cursor as cursor
    use lexer.text as text

    var start = cursor
    var state = Start
    var nesting = 0

    for i, c in text[cursor..] {
        match state {
            Start:
                start = cursor + i
                match c {
                    'a'..'z':
                    'A'..'Z':
                    '_':
                          state = Identifier
                    '0'..'9':
                          state = Number
                    '\'': state = SingleQuote
                    '"':  state = DoubleQuote
                    '=':  state = Equal
                    '<':  state = AngleBracketLeft
                    '>':  state = AngleBracketRight
                    '*':  state = Asterisk
                    '/':  state = Slash
                    '%':  state = Percent
                    '+':  state = Plus
                    '-':  state = Minus
                    '&':  state = Ampersand
                    '|':  state = Pipe
                    '^':  state = Caret
                    '.':  state = Dot
                    ' ': 
                    '\t': 
                        start += 1
                        continue
                    '\n':
                    '\r':
                        cursor = cursor + i + 1
                        return Token(Newline, text[start .. cursor])
                    '{':
                        cursor = cursor + i + 1
                        return Token(LBrace, text[start .. cursor])
                    '}':
                        cursor = cursor + i + 1
                        return Token(RBrace, text[start .. cursor])
                    '[':
                        cursor = cursor + i + 1
                        return Token(LBracket, text[start .. cursor])
                    ']':
                        cursor = cursor + i + 1
                        return Token(RBracket, text[start .. cursor])
                    '(':
                        cursor = cursor + i + 1
                        return Token(LParen, text[start .. cursor])
                    ')':
                        cursor = cursor + i + 1
                        return Token(RParen, text[start .. cursor])
                    ':':
                        cursor = cursor + i + 1
                        return Token(Colon, text[start .. cursor])
                    ',': 
                        cursor = cursor + i + 1
                        return Token(Comma, text[start .. cursor])
                    ';':
                        cursor = cursor + i + 1
                        return Token(Semicolon, text[start .. cursor])
                    '~':
                        cursor = cursor + i + 1
                        return Token(Tilde, text[start .. cursor])
                    0:
                        cursor = cursor + i
                        return Token(Eof, text[start .. cursor])
                    else:
                        cursor = cursor + i + 1
                        return Token(Invalid, text[start .. cursor])
                }

            Identifier:
                match c {
                    'a'..'z':
                    'A'..'Z':
                    '0'..'9':
                    '_':
                        continue
                    else:
                        cursor = cursor + i
                        lexeme = text[start .. cursor]
                        return Token(match_keyword(lexeme), lexeme)
                }

            Number:
                match c {
                    '0'..'9': continue
                    else:
                        cursor = cursor + i
                        return Token(Number, text[start .. cursor])
                }

            SingleQuote:
                match c {
                    '\\':
                        continue
                    '\'':
                        cursor = cursor + i + 1
                        return Token(StringLiteral, text[start .. cursor])
                    else:
                        continue
                }

            DoubleQuote:
                match c {
                    '"':
                        cursor = cursor + i + 1
                        return Token(StringLiteral, text[start + 1 .. cursor - 1])
                    else:
                        continue
                }

            Equal:
                match c {
                    '=':
                        cursor = cursor + i + 1
                        return Token(EqualEqual, text[start .. cursor])
                    else:
                        cursor = cursor + i
                        return Token(Equal, text[start .. cursor])
                }

            AngleBracketLeft:
                match c {
                    '=':
                        cursor = cursor + i + 1
                        return Token(AngleBracketLeftEqual, text[start .. cursor])
                    else:
                        cursor = cursor + i
                        return Token(AngleBracketLeft, text[start .. cursor])
                }

            AngleBracketRight:
                match c {
                    '=':
                        cursor = cursor + i + 1
                        return Token(AngleBracketRightEqual, text[start .. cursor])
                    else:
                        cursor = cursor + i
                        return Token(AngleBracketRight, text[start .. cursor])
                }

            Asterisk:
                match c {
                    '=':
                        cursor = cursor + i + 1
                        return Token(AsteriskEqual, text[start .. cursor])
                    else:
                        cursor = cursor + i
                        return Token(Asterisk, text[start .. cursor])
                }

            Percent:
                match c {
                    '=':
                        cursor = cursor + i + 1
                        return Token(PercentEqual, text[start .. cursor])
                    else:
                        cursor = cursor + i
                        return Token(Percent, text[start .. cursor])
                }

            Plus:
                match c {
                    '=':
                        cursor = cursor + i + 1
                        return Token(PlusEqual, text[start .. cursor])
                    else:
                        cursor = cursor + i
                        return Token(Plus, text[start .. cursor])
                }

            Minus:
                match c {
                    '=':
                        cursor = cursor + i + 1
                        return Token(MinusEqual, text[start .. cursor])
                    else:
                        cursor = cursor + i
                        return Token(Minus, text[start .. cursor])
                }

            Ampersand:
                match c {
                    '=':
                        cursor = cursor + i + 1
                        return Token(AmpersandEqual, text[start .. cursor])
                    else:
                        cursor = cursor + i
                        return Token(Ampersand, text[start .. cursor])
                }

            Pipe:
                match c {
                    '=':
                        cursor = cursor + i + 1
                        return Token(PipeEqual, text[start .. cursor])
                    else:
                        cursor = cursor + i
                        return Token(Pipe, text[start .. cursor])
                }

            Caret:
                match c {
                    '=':
                        cursor = cursor + i + 1
                        return Token(CaretEqual, text[start .. cursor])
                    else:
                        cursor = cursor + i
                        return Token(Caret, text[start .. cursor])
                }

            Dot:
                match c {
                    '.': state = DotDot
                    else:
                        cursor = cursor + i
                        return Token(Period, text[start .. cursor])
                }

            DotDot:
                match c {
                    '=':
                        cursor = cursor + i + 1
                        return Token(DotDotEqual, text[start .. cursor])
                    else:
                        cursor = cursor + i
                        return Token(DotDot, text[start .. cursor])
                }

            Slash:
                match c {
                    '/':
                        state = LineComment
                    '*':
                        state = MultilineComment
                        nesting = 1
                    '=':
                        cursor = cursor + i + 1
                        return Token(SlashEqual, text[start .. cursor])
                    else:
                        cursor = cursor + i
                        return Token(Slash, text[start .. cursor])
                }

            LineComment:
                match c {
                    '\n':
                    '\r':
                    0:
                        cursor = cursor + i
                        return Token(LineComment, text[start .. cursor])
                    else:
                        continue
                }

            MultilineComment:
                if c == '/' and text[cursor + i + 1] == '*' {
                    nesting += 1
                } else if c == '*' and text[cursor + i + 1] == '/' {
                    nesting -= 1
                    if nesting == 0 {
                        cursor = cursor + i + 2
                        return Token(MultilineComment, text[start .. cursor])
                    }
                } else if c == 0 {
                    cursor = cursor + i
                    return Token(MultilineComment, text[start .. cursor])
                }
        }
    }

    // End of file fallback
    cursor = len(text)
    return Token(Eof, text[cursor .. cursor])
}




func next(lexer Lexer) Token {
    use lexer.cursor as cursor
    use lexer.text as text

    var state = Start
    var start = cursor
    
    for i, c in text[cursor..] {
    
        switch state {
            Start:

        }
    }
}





func main() void {
    lexer = Lexer("example\0", 0)
}




type Kind {
    Invalid
    Eof
    Newline
    Identifier
    Number
    StringLiteral
    LParen
    RParen
    LBracket
    RBracket
    LBrace
    RBrace
    Period
    Comma
    Colon
    Semicolon
    Tilde
    Equal
    EqualEqual
    AngleBracketLeft
    AngleBracketLeftEqual
    AngleBracketRight
    AngleBracketRightEqual
    Asterisk
    AsteriskEqual
    Slash
    SlashEqual
    Plus
    PlusEqual
    Minus
    MinusEqual
    Ampersand
    AmpersandEqual
    Pipe
    PipeEqual
    Caret
    CaretEqual
    Percent
    PercentEqual
    LineComment
    MultilineComment
    KeywordIf
    KeywordEnd
    KeywordFor
    KeywordType
    KeywordFunc
    KeywordProc
    KeywordExpr
    KeywordElif
    KeywordElse
    KeywordCase
    KeywordMacro
    KeywordMatch
    KeywordImport
    KeywordExport
}

type Token {
    kind   Kind
    lexeme u8[]
}

type State {
    Start
    Identifier
    Number
    SingleQuote
    DoubleQuote
    LineComment
    MultilineComment
    Equal
    AngleBracketLeft
    AngleBracketRight
    Asterisk
    Slash
    Percent
    Plus
    Minus
    Ampersand
    Pipe
    Caret
    Dot
    DotDot
}

type Lexer {
    text   u8[:0]
    cursor u8
}

func next(lexer Lexer) Token {
    use lexer.cursor as cursor
    use lexer.text as text

    var state = Start
    var start = cursor
    
    for i, c in text[cursor..] {
    
        switch state {
            Start:
                match c {
                    'a'..'z':
                    'A'..'Z':
                    '_':
                          state = Identifier
                    '0'..'9':
                          state = Number
                    '\'': state = SingleQuote
                    '"':  state = DoubleQuote
                    '=':  state = Equal
                    '<':  state = AngleBracketLeft
                    '>':  state = AngleBracketRight
                    '*':  state = Asterisk
                    '/':  state = Slash
                    '%':  state = Percent
                    '+':  state = Plus
                    '-':  state = Minus
                    '&':  state = Ampersand
                    '|':  state = Pipe
                    '^':  state = Caret
                    '.':  state = Dot
                    ' ': 
                    '\t': 
                        start += 1
                        continue
                    '\n':
                    '\r':
                        cursor = cursor + i + 1
                        return Token(Newline, text[start .. cursor])
                    '{':
                        cursor = cursor + i + 1
                        return Token(LBrace, text[start .. cursor])
                    '}':
                        cursor = cursor + i + 1
                        return Token(RBrace, text[start .. cursor])
                    '[':
                        cursor = cursor + i + 1
                        return Token(LBracket, text[start .. cursor])
                    ']':
                        cursor = cursor + i + 1
                        return Token(RBracket, text[start .. cursor])
                    '(':
                        cursor = cursor + i + 1
                        return Token(LParen, text[start .. cursor])
                    ')':
                        cursor = cursor + i + 1
                        return Token(RParen, text[start .. cursor])
                    ':':
                        cursor = cursor + i + 1
                        return Token(Colon, text[start .. cursor])
                    ',': 
                        cursor = cursor + i + 1
                        return Token(Comma, text[start .. cursor])
                    ';':
                        cursor = cursor + i + 1
                        return Token(Semicolon, text[start .. cursor])
                    '~':
                        cursor = cursor + i + 1
                        return Token(Tilde, text[start .. cursor])
                    0:
                        cursor = cursor + i
                        return Token(Eof, text[start .. cursor])
                    else:
                        cursor = cursor + i + 1
                        return Token(Invalid, text[start .. cursor])
                }

        }
    }
}



import c.stdio
import c.string
import c.stddef

extern func printf(fmt u8[:0], ...) int















type Lexer {
    text   u8[:0]
    cursor u8 //in text
}

type Token {
    kind   Kind
    lexeme u8[] //in Lexer.text
}

type Lexer.State {
    Start
    Plus
}

type Token.Kind {
    Plus
    PlusPlus
    Minus
}

func next(lexer Lexer) Token {
    use lexer.cursor as cursor
    use lexer.text as text

    var state = Start
    var start = cursor

    for cursor, c in text[cursor..] {
        switch state {

            Start:

                switch c {
                    "+":
                        state = Plus

                    "-":
                        return Token(Minus, text[start .. cursor])
                }
        }
    }
}

func main() int {
    lexer = Lexer("+-++\0", 0)
}




fun alloc(var size Int, mov ptr Ptr) mov Alloc // a "mov" type is forced to move before end of scope. (same as Linear type)

fun main() {
    p var int = malloc(sizeof(u8))

}


// GO:

func divide(a, b int) (quotient int, remainder int) {
    quotient = a / b
    remainder = a % b
    return // returns quotient, remainder
}




type Transaction {
    id int
}

func make(id int ) mov Transaction {
    return Transaction(id)
}

func consume(mov txn Transaction) int {
    return txn.id
}

func main() int {
    printf("Hello World!\n")

    txn = make(1)
    id  = consume(txn)
    
    printf("%i\n", id)
}

/*
type Transaction {
    id int
}

func make(id int ) Transaction' {
    Transaction(id)
}

func consume(txn Transaction') int {
    txn.id
}

proc main() int {
    printf("Hello World!\n")

    txn = make(1)
    id  = consume(txn)
    
    printf("%i\n", id)
}
*/

func print_s(s u8[]) void {
    tmp = s.data
    printf("%s", tmp)
}

func main() int {
    s = "hello World!\n"
    print_s(s)
}





type Kind {
    Eof
    Plus
    Minus
}

type Token {
    kind   Kind
    lexeme u8[]
}

type Lexer {
    text   u8[:0]
    cursor u8 in text
}

type State {
    Start
}

func next(lexer Lexer) Token {

}

func main() i32 {
    lexer = Lexer("+-++-", 0)



}













type Kind {
    Eof
    Plus
    PlusPlus
    Minus
    MinusMinus
}

type Token {
    kind   Kind
    lexeme u8[]
}

type Lexer {
    text u8[:0]
    var cursor u8 in text
}

type State {
    Start
    Plus
    Minus
}

iter next(lexer Lexer) Token {
    var begin = cursor
    var state = Start

    for cursor, c in text[cursor..] {

        match state {

            Start:
                match c {
                    '+':    state = Plus
                    '-':    state = Minus
                }
            Plus :
                match c {
                    '+':    yield Token(PlusPlus, text[begin..cursor])
                    else:
                            yield Token(Plus, text[begin..cursor])
                            goto Start
                }
            Minus:
                match c {
                    '-':    yield Token(MinusMinus, text[begin..cursor])
                    else:
                            yield Token(Minus, text[begin..cursor])
                            goto Start
                }

        }
    }

    return Token(Eof, text[begin..cursor])
}

func main() i32 {
    lexer = Lexer("+-++--", 0)

    for token in lexer.next() while token != Eof {
        
    }

    while token in lexer.next() != Eof {
        
    }


}

























type Kind {
    Eof
    Plus
    PlusPlus
    Minus
    MinusMinus
}

type Token {
    kind   Kind
    lexeme u8[]
}

type Lexer {
    text u8[:0]
}

type State {
    Start
    Plus
    Minus
}

iter next(lexer Lexer) Token {
    var begin = cursor
    var state = Start
-
    for cursor, c in text {

        case state {

            Start:
                case c {
                    '+':    state = Plus
                    '-':    state = Minus
                }
            Plus :
                case c {
                    '+':    yield Token(PlusPlus, text[begin..cursor])
                    else:
                            yield Token(Plus, text[begin..cursor])
                            goto Start
                }
            Minus:
                case c {
                    '-':    yield Token(MinusMinus, text[begin..cursor])
                    else:
                            yield Token(Minus, text[begin..cursor])
                            goto Start
                }

        }
    }

    return Token(Eof, text[begin..cursor])
}

func main() i32 {
    lexer = Lexer("+-++--", 0)

    for token in lexer.next() while token != Eof {
        
    }

    while token in lexer.next() != Eof {
        
    }


    arr = [5, 3, 6, 4, 9]

    var sum = 0
    for i in arr {
        sum += arr[i]
    }

    int sum = 0;
    for (int i = 0; i < n; i++) {
        sum += array[i];
    }


}